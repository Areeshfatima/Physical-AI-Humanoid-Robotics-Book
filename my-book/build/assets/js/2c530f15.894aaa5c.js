"use strict";(globalThis.webpackChunkmy_book=globalThis.webpackChunkmy_book||[]).push([[526],{3023(n,e,i){i.d(e,{R:()=>s,x:()=>r});var o=i(3696);const t={},a=o.createContext(t);function s(n){const e=o.useContext(a);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),o.createElement(a.Provider,{value:e},n.children)}},9500(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module-3-isaac/chapter-4","title":"Isaac Applications and Deployment","description":"Deploying and applying NVIDIA Isaac robotics solutions in real-world scenarios","source":"@site/docs/module-3-isaac/chapter-4.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/chapter-4","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3-isaac/chapter-4","draft":false,"unlisted":false,"editUrl":"undefined/docs/module-3-isaac/chapter-4.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Isaac Applications and Deployment","sidebar_position":5,"description":"Deploying and applying NVIDIA Isaac robotics solutions in real-world scenarios","keywords":["nvidia","isaac","deployment","applications","robotics","ai","edge","jetson"],"id":"chapter-4"},"sidebar":"textbookSidebar","previous":{"title":"AI Integration with Isaac Sim (Omniverse)","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3-isaac/chapter-3"},"next":{"title":"Vision-Language-Action (VLA) Models for Robotics","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/"}}');var t=i(2540),a=i(3023);const s={title:"Isaac Applications and Deployment",sidebar_position:5,description:"Deploying and applying NVIDIA Isaac robotics solutions in real-world scenarios",keywords:["nvidia","isaac","deployment","applications","robotics","ai","edge","jetson"],id:"chapter-4"},r="Isaac Applications and Deployment",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Isaac Deployment",id:"introduction-to-isaac-deployment",level:2},{value:"Hardware Platforms for Isaac",id:"hardware-platforms-for-isaac",level:2},{value:"NVIDIA Jetson Platform",id:"nvidia-jetson-platform",level:3},{value:"Jetson AGX Xavier",id:"jetson-agx-xavier",level:4},{value:"Jetson Orin",id:"jetson-orin",level:4},{value:"Jetson Nano",id:"jetson-nano",level:4},{value:"Deployment on Jetson Platform",id:"deployment-on-jetson-platform",level:3},{value:"NVIDIA RTX and Data Center Deployment",id:"nvidia-rtx-and-data-center-deployment",level:3},{value:"Isaac Application Framework",id:"isaac-application-framework",level:2},{value:"Isaac Apps Architecture",id:"isaac-apps-architecture",level:3},{value:"Navigation Application Deployment",id:"navigation-application-deployment",level:3},{value:"Manipulation Application Deployment",id:"manipulation-application-deployment",level:3},{value:"Deployment Strategies",id:"deployment-strategies",level:2},{value:"Edge Deployment",id:"edge-deployment",level:3},{value:"Cloud-Edge Hybrid Deployment",id:"cloud-edge-hybrid-deployment",level:3},{value:"System Integration and Configuration",id:"system-integration-and-configuration",level:2},{value:"Isaac System Configuration",id:"isaac-system-configuration",level:3},{value:"Launch Configuration",id:"launch-configuration",level:3},{value:"Production Deployment Considerations",id:"production-deployment-considerations",level:2},{value:"Container Orchestration",id:"container-orchestration",level:3},{value:"Monitoring and Health Checks",id:"monitoring-and-health-checks",level:3},{value:"Common Deployment Scenarios",id:"common-deployment-scenarios",level:2},{value:"Autonomous Mobile Robot (AMR)",id:"autonomous-mobile-robot-amr",level:3},{value:"Troubleshooting and Performance Optimization",id:"troubleshooting-and-performance-optimization",level:2},{value:"Common Issues and Solutions",id:"common-issues-and-solutions",level:3},{value:"Performance Monitoring Tools",id:"performance-monitoring-tools",level:3},{value:"Operational Considerations",id:"operational-considerations",level:2},{value:"Maintenance and Updates",id:"maintenance-and-updates",level:3},{value:"Security Best Practices",id:"security-best-practices",level:3},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"isaac-applications-and-deployment",children:"Isaac Applications and Deployment"})}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"After completing this chapter, you should be able to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Deploy Isaac-based solutions on NVIDIA hardware platforms"}),"\n",(0,t.jsx)(e.li,{children:"Configure Isaac applications for different robotics platforms"}),"\n",(0,t.jsx)(e.li,{children:"Implement deployment strategies for various use cases"}),"\n",(0,t.jsx)(e.li,{children:"Troubleshoot and optimize deployed Isaac applications"}),"\n",(0,t.jsx)(e.li,{children:"Understand the operational aspects of Isaac-based robots"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"introduction-to-isaac-deployment",children:"Introduction to Isaac Deployment"}),"\n",(0,t.jsx)(e.p,{children:"Deploying Isaac-based robotics solutions involves transitioning from simulation-tested algorithms to real-world applications. The NVIDIA Isaac platform is designed with deployment in mind, offering tools and frameworks that simplify this transition."}),"\n",(0,t.jsx)(e.p,{children:"Key deployment concepts include:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Hardware platform selection and optimization"}),"\n",(0,t.jsx)(e.li,{children:"Software containerization and orchestration"}),"\n",(0,t.jsx)(e.li,{children:"Real-time performance optimization"}),"\n",(0,t.jsx)(e.li,{children:"System integration and testing"}),"\n",(0,t.jsx)(e.li,{children:"Operational considerations (monitoring, maintenance, updates)"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"hardware-platforms-for-isaac",children:"Hardware Platforms for Isaac"}),"\n",(0,t.jsx)(e.h3,{id:"nvidia-jetson-platform",children:"NVIDIA Jetson Platform"}),"\n",(0,t.jsx)(e.p,{children:"The NVIDIA Jetson platform is specifically designed for edge AI and robotics applications. Isaac is optimized to run on various Jetson modules:"}),"\n",(0,t.jsx)(e.h4,{id:"jetson-agx-xavier",children:"Jetson AGX Xavier"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Compute"}),": 32 TOPS AI performance"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"GPU"}),": 512-core Volta GPU with Tensor Cores"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"CPU"}),": 8-core ARM v8.2 64-bit CPU"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Memory"}),": 32GB 256-bit LPDDR4x"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Best for"}),": Complex perception and planning tasks"]}),"\n"]}),"\n",(0,t.jsx)(e.h4,{id:"jetson-orin",children:"Jetson Orin"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Compute"}),": Up to 275 TOPS AI performance"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"GPU"}),": Next-generation NVIDIA GPU with Tensor Cores"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"CPU"}),": 12-core ARM v8.2 64-bit CPU"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Memory"}),": Up to 64GB LPDDR5"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Best for"}),": Next-generation robotics applications"]}),"\n"]}),"\n",(0,t.jsx)(e.h4,{id:"jetson-nano",children:"Jetson Nano"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Compute"}),": 472 GFLOPS AI performance"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"GPU"}),": 128-core Maxwell GPU"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"CPU"}),": Quad-core ARM A57 CPU"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Memory"}),": 4GB LPDDR4"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Best for"}),": Educational and simple robotics projects"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"deployment-on-jetson-platform",children:"Deployment on Jetson Platform"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Example Isaac ROS application for Jetson deployment\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom vision_msgs.msg import Detection2DArray\nfrom std_msgs.msg import String\nimport cv2\nfrom cv_bridge import CvBridge\nimport numpy as np\n\nclass IsaacJetsonDeployment(Node):\n    def __init__(self):\n        super().__init__(\'isaac_jetson_deployment\')\n        \n        # Initialize CV bridge\n        self.cv_bridge = CvBridge()\n        \n        # Subscribe to camera data\n        self.camera_sub = self.create_subscription(\n            Image,\n            \'/camera/rgb\',\n            self.camera_callback,\n            10\n        )\n        \n        # Publisher for AI detections\n        self.detection_pub = self.create_publisher(\n            Detection2DArray,\n            \'/isaac_jetson/detections\',\n            10\n        )\n        \n        # Publisher for system status\n        self.status_pub = self.create_publisher(\n            String,\n            \'/isaac_jetson/status\',\n            10\n        )\n        \n        # Initialize AI models optimized for Jetson\n        self.initialize_jetson_models()\n        \n        # Timer for system health monitoring\n        self.status_timer = self.create_timer(5.0, self.status_callback)\n        \n        self.get_logger().info(\'Isaac Jetson Deployment Node Started\')\n    \n    def initialize_jetson_models(self):\n        """\n        Initialize AI models optimized for Jetson hardware\n        """\n        try:\n            # Load TensorRT optimized models for Jetson\n            import tensorrt as trt\n            from isaac_ros_tensor_rt.tensor_rt_model import TensorRTModel\n            \n            self.detection_model = TensorRTModel(\n                engine_path=\'/opt/nvidia/isaac/models/detection_model.plan\'\n            )\n            \n            self.get_logger().info(\'AI models loaded successfully\')\n        except Exception as e:\n            self.get_logger().error(f\'Failed to load AI models: {e}\')\n    \n    def camera_callback(self, msg):\n        """\n        Process incoming camera data and run AI inference\n        """\n        try:\n            # Convert ROS image to OpenCV format\n            cv_image = self.cv_bridge.imgmsg_to_cv2(msg, desired_encoding=\'bgr8\')\n            \n            # Run object detection (optimized for Jetson)\n            detections = self.run_jetson_detection(cv_image)\n            \n            # Publish results\n            self.publish_detections(detections, msg.header)\n            \n            # Log performance metrics\n            self.get_logger().debug(\'Processed image with AI model\')\n        except Exception as e:\n            self.get_logger().error(f\'Error processing camera data: {e}\')\n    \n    def run_jetson_detection(self, image):\n        """\n        Run optimized object detection on Jetson hardware\n        """\n        # Preprocess image for inference\n        input_tensor = self.preprocess_jetson_input(image)\n        \n        # Run inference using optimized model\n        outputs = self.detection_model.infer(input_tensor)\n        \n        # Process outputs\n        detections = self.process_jetson_outputs(outputs)\n        \n        return detections\n    \n    def preprocess_jetson_input(self, image):\n        """\n        Preprocess image for Jetson-optimized inference\n        """\n        # Resize image to model input size\n        resized = cv2.resize(image, (640, 640))\n        \n        # Normalize image values\n        normalized = resized.astype(np.float32) / 255.0\n        \n        # Transpose to channel-first format\n        input_tensor = np.transpose(normalized, (2, 0, 1))\n        \n        # Add batch dimension\n        input_tensor = np.expand_dims(input_tensor, axis=0)\n        \n        return input_tensor.astype(np.float32)\n    \n    def process_jetson_outputs(self, outputs):\n        """\n        Process outputs from Jetson-optimized model\n        """\n        # Extract detection results (model-specific implementation)\n        # This would parse the raw outputs from the TensorRT model\n        pass\n    \n    def publish_detections(self, detections, header):\n        """\n        Publish AI detection results in ROS format\n        """\n        # Implementation for publishing detection messages\n        pass\n    \n    def status_callback(self):\n        """\n        Publish system status information\n        """\n        import psutil\n        import GPUtil\n        \n        # Monitor system resources\n        cpu_percent = psutil.cpu_percent()\n        memory_percent = psutil.virtual_memory().percent\n        \n        # Get GPU information (for Jetson)\n        try:\n            # On Jetson, we might use nvidia-ml-py or jetson-stats\n            import subprocess\n            gpu_info = subprocess.check_output([\'nvpmodel\', \'-q\'], encoding=\'utf-8\')\n            gputil = \'N/A\'  # Placeholder for Jetson GPU utilization\n        except:\n            gputil = \'N/A\'\n        \n        status_msg = String()\n        status_msg.data = f\'CPU: {cpu_percent}%, Memory: {memory_percent}%, GPU: {gputil}%\'\n        \n        self.status_pub.publish(status_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = IsaacJetsonDeployment()\n    \n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info(\'Shutting down Isaac Jetson Deployment Node\')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,t.jsx)(e.h3,{id:"nvidia-rtx-and-data-center-deployment",children:"NVIDIA RTX and Data Center Deployment"}),"\n",(0,t.jsx)(e.p,{children:"For more computationally intensive tasks or multi-robot coordination:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"RTX A6000"}),": For complex simulation and training tasks"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"DGX Systems"}),": For large-scale AI model training"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Omniverse Enterprise"}),": For multi-user simulation environments"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"isaac-application-framework",children:"Isaac Application Framework"}),"\n",(0,t.jsx)(e.h3,{id:"isaac-apps-architecture",children:"Isaac Apps Architecture"}),"\n",(0,t.jsx)(e.p,{children:"Isaac Apps provide pre-built applications for common robotics tasks:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Isaac Application                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Perception     \u2502 Navigation  \u2502 Manipulation \u2502 Others  \u2502\n\u2502  - Object Det.  \u2502  - Path     \u2502 - Grasp      \u2502 - SLAM   \u2502\n\u2502  - Segmentation \u2502    Planning \u2502   Planning   \u2502 - Mapping\u2502\n\u2502  - Tracking     \u2502  - Localiz. \u2502 - Force Ctrl \u2502 - Control\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n              \u25bc\n    Isaac ROS Hardware Abstraction\n              \u2502\n              \u25bc\n    ROS 2 Middleware & Tools\n              \u2502\n              \u25bc\n   Hardware Drivers & Interfaces\n"})}),"\n",(0,t.jsx)(e.h3,{id:"navigation-application-deployment",children:"Navigation Application Deployment"}),"\n",(0,t.jsx)(e.p,{children:"Example deployment of Isaac Navigation application:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Deploy Isaac Navigation using Docker\ndocker run --gpus all \\\n    --env NVIDIA_DISABLE_REQUIRE=1 \\\n    --rm -it \\\n    --network=host \\\n    --privileged \\\n    --volume /tmp/.X11-unix:/tmp/.X11-unix:rw \\\n    --volume /opt/nvidia/isaac:/opt/nvidia/isaac:ro \\\n    --volume /home/user/maps:/maps:rw \\\n    --device=/dev:/dev \\\n    --env DISPLAY=$DISPLAY \\\n    --env TERM=xterm-color \\\n    --env ROS_DOMAIN_ID=1 \\\n    --name isaac-navigation \\\n    nvcr.io/nvidia/isaac/navigation:latest\n"})}),"\n",(0,t.jsx)(e.h3,{id:"manipulation-application-deployment",children:"Manipulation Application Deployment"}),"\n",(0,t.jsx)(e.p,{children:"Example of deploying Isaac Manipulation application:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# Docker Compose file for Isaac Manipulation\nversion: \'3.8\'\n\nservices:\n  isaac-manipulation:\n    image: nvcr.io/nvidia/isaac/manipulation:latest\n    container_name: isaac-manipulation\n    runtime: nvidia\n    environment:\n      - NVIDIA_DISABLE_REQUIRE=1\n      - ROS_DOMAIN_ID=1\n      - NVIDIA_VISIBLE_DEVICES=all\n    volumes:\n      - /tmp/.X11-unix:/tmp/.X11-unix:rw\n      - /opt/nvidia/isaac:/opt/nvidia/isaac:ro\n      - ./calibration:/calibration:rw\n    devices:\n      - /dev:/dev\n    network_mode: host\n    privileged: true\n    stdin_open: true\n    tty: true\n    command: ["bash", "-c", "source /opt/ros/humble/setup.bash && ros2 launch isaac_ros_manipulation manipulation.launch.py"]\n'})}),"\n",(0,t.jsx)(e.h2,{id:"deployment-strategies",children:"Deployment Strategies"}),"\n",(0,t.jsx)(e.h3,{id:"edge-deployment",children:"Edge Deployment"}),"\n",(0,t.jsx)(e.p,{children:"For edge robotics applications, consider:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Resource Constraints"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Optimize AI models for inference on edge hardware"}),"\n",(0,t.jsx)(e.li,{children:"Use quantization and pruning techniques"}),"\n",(0,t.jsx)(e.li,{children:"Implement efficient memory management"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Real-Time Requirements"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Optimize computational pipelines for real-time performance"}),"\n",(0,t.jsx)(e.li,{children:"Implement efficient sensor fusion"}),"\n",(0,t.jsx)(e.li,{children:"Use hardware acceleration features"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Power Management"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Optimize for power-efficient operation"}),"\n",(0,t.jsx)(e.li,{children:"Implement adaptive computing based on task requirements"}),"\n",(0,t.jsx)(e.li,{children:"Monitor thermal constraints"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"cloud-edge-hybrid-deployment",children:"Cloud-Edge Hybrid Deployment"}),"\n",(0,t.jsx)(e.p,{children:"For applications requiring both local autonomy and cloud connectivity:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Example of cloud-edge hybrid architecture\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom vision_msgs.msg import Detection2DArray\nimport requests\nimport threading\nimport queue\n\nclass HybridDeploymentNode(Node):\n    def __init__(self):\n        super().__init__(\'hybrid_deployment\')\n        \n        # Local processing\n        self.local_sub = self.create_subscription(\n            Image,\n            \'/camera/rgb\',\n            self.local_processing_callback,\n            10\n        )\n        \n        self.local_pub = self.create_publisher(\n            Detection2DArray,\n            \'/local_detections\',\n            10\n        )\n        \n        # Cloud processing\n        self.cloud_pub = self.create_publisher(\n            Detection2DArray,\n            \'/cloud_detections\',\n            10\n        )\n        \n        # Initialize processing queues\n        self.cloud_processing_queue = queue.Queue(maxsize=10)\n        \n        # Start cloud processing thread\n        self.cloud_thread = threading.Thread(target=self.cloud_processing_worker)\n        self.cloud_thread.daemon = True\n        self.cloud_thread.start()\n    \n    def local_processing_callback(self, msg):\n        """\n        Process image with local AI model first\n        """\n        # Run local AI model (fast, less accurate)\n        local_detections = self.run_local_ai(msg)\n        self.local_pub.publish(local_detections)\n        \n        # Send to cloud for more complex analysis (if needed)\n        if self.need_cloud_analysis(local_detections):\n            self.cloud_processing_queue.put(msg)\n    \n    def run_local_ai(self, image_msg):\n        """\n        Run lightweight AI model on edge device\n        """\n        # Implementation of local AI inference\n        pass\n    \n    def need_cloud_analysis(self, detections):\n        """\n        Determine if cloud analysis is needed\n        """\n        # Logic to decide when to use cloud resources\n        # e.g., if local model confidence is low\n        return False\n    \n    def cloud_processing_worker(self):\n        """\n        Process images on cloud in separate thread\n        """\n        while True:\n            try:\n                image_msg = self.cloud_processing_queue.get(timeout=1.0)\n                \n                # Send image to cloud API\n                cloud_results = self.send_to_cloud(image_msg)\n                \n                if cloud_results:\n                    self.cloud_pub.publish(cloud_results)\n                \n                self.cloud_processing_queue.task_done()\n            except queue.Empty:\n                continue\n    \n    def send_to_cloud(self, image_msg):\n        """\n        Send image to cloud for processing\n        """\n        # Convert ROS image to appropriate format\n        # Send to cloud API\n        # Return processed results\n        pass\n'})}),"\n",(0,t.jsx)(e.h2,{id:"system-integration-and-configuration",children:"System Integration and Configuration"}),"\n",(0,t.jsx)(e.h3,{id:"isaac-system-configuration",children:"Isaac System Configuration"}),"\n",(0,t.jsx)(e.p,{children:"Example configuration for a complete Isaac robotics system:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# isaac_system_config.yaml\nsystem:\n  name: "IsaacRobot"\n  version: "3.0"\n  domain_id: 1\n\nhardware:\n  robot:\n    type: "mobile_manipulator"\n    model: "franka_panda"\n    urdf_path: "/opt/nvidia/isaac/models/franka_panda.urdf"\n  sensors:\n    - type: "camera"\n      topic: "/camera/rgb"\n      resolution: [640, 480]\n      frequency: 30\n    - type: "lidar"\n      topic: "/lidar/scan"\n      range: 10.0\n      resolution: 0.01\n  actuators:\n    - type: "joint"\n      controller: "position"\n      frequency: 100\n\nai_models:\n  detection:\n    engine_path: "/models/detection.plan"\n    input_size: [3, 640, 640]\n    confidence_threshold: 0.5\n  segmentation:\n    engine_path: "/models/segmentation.plan"\n    input_size: [3, 512, 512]\n\nnavigation:\n  planner:\n    type: "teb"\n    global_update_rate: 1.0\n    local_update_rate: 5.0\n  costmap:\n    resolution: 0.05\n    inflation_radius: 0.55\n\nmanipulation:\n  grasping:\n    approach_distance: 0.1\n    grasp_depth: 0.05\n    gripper_width: 0.08\n\nperformance:\n  cpu_affinity: [2, 3, 4, 5]\n  gpu_memory_fraction: 0.8\n  real_time_qos: true\n\nlogging:\n  level: "INFO"\n  file_path: "/var/log/isaac_robot.log"\n'})}),"\n",(0,t.jsx)(e.h3,{id:"launch-configuration",children:"Launch Configuration"}),"\n",(0,t.jsx)(e.p,{children:"Example ROS 2 launch file for Isaac system:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"# isaac_robot.launch.py\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\nfrom ament_index_python.packages import get_package_share_directory\nimport os\n\ndef generate_launch_description():\n    # Launch arguments\n    use_sim_time = LaunchConfiguration('use_sim_time', default='false')\n    config_file = LaunchConfiguration('config_file', default='isaac_system_config.yaml')\n    \n    # Isaac ROS components\n    # Perception pipeline\n    perception_nodes = [\n        Node(\n            package='isaac_ros_detection',\n            executable='detection_node',\n            name='detection_node',\n            parameters=[\n                PathJoinSubstitution([\n                    FindPackageShare('isaac_ros_detection'),\n                    'config',\n                    config_file\n                ])\n            ],\n            condition=LaunchConfiguration('perception_enabled', default='true')\n        ),\n        \n        Node(\n            package='isaac_ros_range_image_segmentation',\n            executable='range_image_segmentation_node',\n            name='range_image_segmentation_node',\n            parameters=[\n                PathJoinSubstitution([\n                    FindPackageShare('isaac_ros_range_image_segmentation'),\n                    'config',\n                    config_file\n                ])\n            ],\n            condition=LaunchConfiguration('segmentation_enabled', default='true')\n        )\n    ]\n    \n    # Navigation stack\n    navigation_launch = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource([\n            PathJoinSubstitution([\n                FindPackageShare('isaac_ros_navigation'),\n                'launch',\n                'navigation.launch.py'\n            ])\n        ]),\n        condition=LaunchConfiguration('navigation_enabled', default='true')\n    )\n    \n    # Manipulation stack\n    manipulation_launch = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource([\n            PathJoinSubstitution([\n                FindPackageShare('isaac_ros_manipulation'),\n                'launch',\n                'manipulation.launch.py'\n            ])\n        ]),\n        condition=LaunchConfiguration('manipulation_enabled', default='true')\n    )\n    \n    return LaunchDescription([\n        DeclareLaunchArgument('use_sim_time', default_value='false'),\n        DeclareLaunchArgument('config_file', default_value='isaac_system_config.yaml'),\n        DeclareLaunchArgument('perception_enabled', default_value='true'),\n        DeclareLaunchArgument('navigation_enabled', default_value='true'),\n        DeclareLaunchArgument('manipulation_enabled', default_value='true'),\n    ] + perception_nodes + [\n        navigation_launch,\n        manipulation_launch\n    ])\n"})}),"\n",(0,t.jsx)(e.h2,{id:"production-deployment-considerations",children:"Production Deployment Considerations"}),"\n",(0,t.jsx)(e.h3,{id:"container-orchestration",children:"Container Orchestration"}),"\n",(0,t.jsx)(e.p,{children:"For production deployments, consider using container orchestration:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# k8s-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: isaac-robot-deployment\n  labels:\n    app: isaac-robot\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: isaac-robot\n  template:\n    metadata:\n      labels:\n        app: isaac-robot\n    spec:\n      containers:\n      - name: isaac-robot\n        image: nvcr.io/nvidia/isaac/robot:latest\n        resources:\n          requests:\n            nvidia.com/gpu: 1\n            memory: "4Gi"\n            cpu: "2"\n          limits:\n            nvidia.com/gpu: 1\n            memory: "8Gi"\n            cpu: "4"\n        env:\n        - name: ROS_DOMAIN_ID\n          value: "1"\n        - name: NVIDIA_VISIBLE_DEVICES\n          value: "all"\n        volumeMounts:\n        - name: robot-config\n          mountPath: /etc/robot\n        - name: robot-data\n          mountPath: /var/lib/robot\n        - name: robot-logs\n          mountPath: /var/log/robot\n        securityContext:\n          privileged: true\n      volumes:\n      - name: robot-config\n        persistentVolumeClaim:\n          claimName: robot-config-pvc\n      - name: robot-data\n        persistentVolumeClaim:\n          claimName: robot-data-pvc\n      - name: robot-logs\n        persistentVolumeClaim:\n          claimName: robot-logs-pvc\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: isaac-robot-service\nspec:\n  selector:\n    app: isaac-robot\n  ports:\n    - protocol: TCP\n      port: 50051\n      targetPort: 50051\n  type: LoadBalancer\n'})}),"\n",(0,t.jsx)(e.h3,{id:"monitoring-and-health-checks",children:"Monitoring and Health Checks"}),"\n",(0,t.jsx)(e.p,{children:"Implement comprehensive monitoring for deployed systems:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# health_monitor.py\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image, LaserScan\nimport psutil\nimport GPUtil\nfrom threading import Thread\nimport time\n\nclass HealthMonitor(Node):\n    def __init__(self):\n        super().__init__(\'health_monitor\')\n        \n        # Publishers for health status\n        self.health_pub = self.create_publisher(String, \'/health_status\', 10)\n        self.diagnostic_pub = self.create_publisher(String, \'/diagnostics\', 10)\n        \n        # Subscribe to sensor topics for health checking\n        self.camera_sub = self.create_subscription(\n            Image, \'/camera/rgb\', self.camera_health_callback, 1\n        )\n        self.lidar_sub = self.create_subscription(\n            LaserScan, \'/lidar/scan\', self.lidar_health_callback, 1\n        )\n        \n        # Timers for system health checks\n        self.health_timer = self.create_timer(5.0, self.system_health_check)\n        self.diagnostics_timer = self.create_timer(30.0, self.run_diagnostics)\n        \n        # Track sensor health status\n        self.camera_healthy = True\n        self.lidar_healthy = True\n        self.last_camera_time = time.time()\n        self.last_lidar_time = time.time()\n        \n        self.get_logger().info(\'Health Monitor Node Started\')\n    \n    def camera_health_callback(self, msg):\n        """Monitor camera health by checking data flow"""\n        self.last_camera_time = time.time()\n    \n    def lidar_health_callback(self, msg):\n        """Monitor LIDAR health by checking data flow"""\n        self.last_lidar_time = time.time()\n    \n    def system_health_check(self):\n        """Check overall system health"""\n        current_time = time.time()\n        \n        # Check sensor timeouts\n        if current_time - self.last_camera_time > 5.0:\n            self.camera_healthy = False\n        else:\n            self.camera_healthy = True\n            \n        if current_time - self.last_lidar_time > 5.0:\n            self.lidar_healthy = False\n        else:\n            self.lidar_healthy = True\n        \n        # Check system resources\n        cpu_percent = psutil.cpu_percent()\n        memory_percent = psutil.virtual_memory().percent\n        \n        try:\n            gpus = GPUtil.getGPUs()\n            gpu_load = gpus[0].load if gpus else 0\n            gpu_memory = gpus[0].memoryUtil if gpus else 0\n        except:\n            gpu_load = gpu_memory = 0\n        \n        # Determine overall health status\n        sensor_healthy = self.camera_healthy and self.lidar_healthy\n        system_healthy = cpu_percent < 80 and memory_percent < 80\n        gpu_healthy = gpu_load < 0.9 and gpu_memory < 0.9\n        \n        overall_status = "HEALTHY" if (sensor_healthy and system_healthy and gpu_healthy) else "ISSUE"\n        \n        health_msg = String()\n        health_msg.data = f"Status: {overall_status} | CPU: {cpu_percent}% | Mem: {memory_percent}% | GPU: {gpu_load*100:.1f}% | Sensors: {self.get_sensor_status()}"\n        \n        self.health_pub.publish(health_msg)\n    \n    def get_sensor_status(self):\n        """Get sensor health status"""\n        status = []\n        if self.camera_healthy:\n            status.append("CAM:OK")\n        else:\n            status.append("CAM:ERROR")\n            \n        if self.lidar_healthy:\n            status.append("LIDAR:OK")\n        else:\n            status.append("LIDAR:ERROR")\n            \n        return " | ".join(status)\n    \n    def run_diagnostics(self):\n        """Run comprehensive diagnostics"""\n        diagnostics_msg = String()\n        diagnostics_msg.data = self.perform_comprehensive_diagnostics()\n        self.diagnostic_pub.publish(diagnostics_msg)\n    \n    def perform_comprehensive_diagnostics(self):\n        """Perform detailed system diagnostics"""\n        # This would include detailed system checks\n        # - Network connectivity\n        # - Storage space\n        # - Sensor calibration status\n        # - AI model performance\n        # - Communication quality\n        return "Comprehensive diagnostics completed"\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = HealthMonitor()\n    \n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info(\'Shutting down Health Monitor\')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,t.jsx)(e.h2,{id:"common-deployment-scenarios",children:"Common Deployment Scenarios"}),"\n",(0,t.jsx)(e.h3,{id:"autonomous-mobile-robot-amr",children:"Autonomous Mobile Robot (AMR)"}),"\n",(0,t.jsx)(e.p,{children:"Deploying Isaac for warehouse and logistics applications:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# amr_deployment.py\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped, Twist\nfrom nav_msgs.msg import Odometry\nfrom action_msgs.msg import GoalStatus\nfrom nav2_msgs.action import NavigateToPose\nimport rclpy.action\nimport math\n\nclass IsaacAMRDeployment(Node):\n    def __init__(self):\n        super().__init__(\'isaac_amr_deployment\')\n        \n        # Navigation action client\n        self.nav_client = rclpy.action.ActionClient(\n            self, \n            NavigateToPose, \n            \'navigate_to_pose\'\n        )\n        \n        # Velocity command publisher\n        self.cmd_vel_pub = self.create_publisher(\n            Twist,\n            \'/cmd_vel\',\n            10\n        )\n        \n        # Odometry subscriber\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            \'/odom\',\n            self.odom_callback,\n            10\n        )\n        \n        # Initialize robot pose tracking\n        self.current_pose = None\n        self.navigation_active = False\n        \n        # Timer for navigation monitoring\n        self.nav_monitor_timer = self.create_timer(1.0, self.monitor_navigation)\n        \n        self.get_logger().info(\'Isaac AMR Deployment Node Started\')\n    \n    def odom_callback(self, msg):\n        """Update current robot pose"""\n        self.current_pose = msg.pose.pose\n    \n    def navigate_to_pose(self, x, y, theta=0.0):\n        """Send navigation goal to Isaac Navigation stack"""\n        if not self.nav_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().error(\'Navigation server not available\')\n            return\n        \n        goal_msg = NavigateToPose.Goal()\n        goal_msg.pose.header.frame_id = \'map\'\n        goal_msg.pose.header.stamp = self.get_clock().now().to_msg()\n        goal_msg.pose.pose.position.x = x\n        goal_msg.pose.pose.position.y = y\n        goal_msg.pose.pose.orientation.z = math.sin(theta / 2.0)\n        goal_msg.pose.pose.orientation.w = math.cos(theta / 2.0)\n        \n        self._send_goal_future = self.nav_client.send_goal_async(\n            goal_msg,\n            feedback_callback=self.navigation_feedback\n        )\n        \n        self._send_goal_future.add_done_callback(self.goal_response_callback)\n        self.navigation_active = True\n    \n    def goal_response_callback(self, future):\n        """Handle navigation goal response"""\n        goal_handle = future.result()\n        if not goal_handle.accepted:\n            self.get_logger().info(\'Navigation goal rejected\')\n            self.navigation_active = False\n            return\n        \n        self.get_logger().info(\'Navigation goal accepted\')\n        self._get_result_future = goal_handle.get_result_async()\n        self._get_result_future.add_done_callback(self.get_result_callback)\n    \n    def get_result_callback(self, future):\n        """Handle navigation result"""\n        result = future.result().result\n        status = future.result().status\n        \n        if status == GoalStatus.STATUS_SUCCEEDED:\n            self.get_logger().info(\'Navigation succeeded\')\n        else:\n            self.get_logger().info(f\'Navigation failed with status: {status}\')\n        \n        self.navigation_active = False\n    \n    def navigation_feedback(self, feedback_msg):\n        """Handle navigation feedback"""\n        feedback = feedback_msg.feedback\n        # Log progress or handle feedback as needed\n        self.get_logger().debug(f\'Navigation progress: {feedback.current_distance}\')\n    \n    def monitor_navigation(self):\n        """Monitor navigation progress and safety"""\n        if self.navigation_active and self.current_pose:\n            # Implement safety checks\n            # - Check for unexpected obstacles\n            # - Ensure navigation is making progress\n            # - Monitor for stuck conditions\n            pass\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = IsaacAMRDeployment()\n    \n    # Example: Navigate to specific location\n    # node.navigate_to_pose(10.0, 5.0, 0.0)\n    \n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info(\'Shutting down Isaac AMR Deployment\')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,t.jsx)(e.h2,{id:"troubleshooting-and-performance-optimization",children:"Troubleshooting and Performance Optimization"}),"\n",(0,t.jsx)(e.h3,{id:"common-issues-and-solutions",children:"Common Issues and Solutions"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Performance Issues"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"GPU memory overflow: Optimize model size, use quantization"}),"\n",(0,t.jsx)(e.li,{children:"CPU bottlenecks: Profile code, optimize algorithms, use multithreading"}),"\n",(0,t.jsx)(e.li,{children:"Network latency: Optimize communication protocols, use compression"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Hardware-specific Issues"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Jetson thermal throttling: Implement thermal management"}),"\n",(0,t.jsx)(e.li,{children:"Memory allocation failures: Optimize memory usage, implement memory pools"}),"\n",(0,t.jsx)(e.li,{children:"Sensor driver conflicts: Verify driver compatibility"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"performance-monitoring-tools",children:"Performance Monitoring Tools"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Monitor GPU usage on Jetson\nsudo tegrastats\n\n# Monitor system resources\nhtop\n\n# Monitor ROS 2 topics\nros2 topic echo /health_status\n\n# Monitor Isaac-specific metrics\nnvidia-smi\n"})}),"\n",(0,t.jsx)(e.h2,{id:"operational-considerations",children:"Operational Considerations"}),"\n",(0,t.jsx)(e.h3,{id:"maintenance-and-updates",children:"Maintenance and Updates"}),"\n",(0,t.jsx)(e.p,{children:"For production deployments, establish procedures for:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Regular software updates"}),"\n",(0,t.jsx)(e.li,{children:"Model retraining and deployment"}),"\n",(0,t.jsx)(e.li,{children:"Hardware maintenance"}),"\n",(0,t.jsx)(e.li,{children:"Data backup and recovery"}),"\n",(0,t.jsx)(e.li,{children:"Security updates"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"security-best-practices",children:"Security Best Practices"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Network Security"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Use ROS 2 security features"}),"\n",(0,t.jsx)(e.li,{children:"Implement network segmentation"}),"\n",(0,t.jsx)(e.li,{children:"Secure communication channels"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Data Protection"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Encrypt sensitive data"}),"\n",(0,t.jsx)(e.li,{children:"Implement access controls"}),"\n",(0,t.jsx)(e.li,{children:"Audit data access"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"Deploying Isaac-based robotics solutions involves careful consideration of hardware platforms, system configuration, and operational requirements. Key success factors include:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Proper hardware selection and optimization for the target application"}),"\n",(0,t.jsx)(e.li,{children:"Comprehensive system integration with appropriate configuration"}),"\n",(0,t.jsx)(e.li,{children:"Robust monitoring and health checking capabilities"}),"\n",(0,t.jsx)(e.li,{children:"Effective deployment strategies for different use cases"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"The Isaac platform provides tools and frameworks that simplify the transition from simulation to real-world deployment. By following best practices for deployment and operation, Isaac-based robots can achieve reliable performance in production environments."}),"\n",(0,t.jsx)(e.p,{children:"With this knowledge of Isaac applications and deployment strategies, you're now equipped to implement comprehensive robotics solutions using the NVIDIA Isaac platform."}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.a,{href:"../../module-4/chapter-1.md",children:"Next: Module 4"})," | ",(0,t.jsx)(e.a,{href:"/Physical-AI-Humanoid-Robotics-Book/docs/module-3-isaac/chapter-3",children:"Previous: AI Integration with Isaac Sim (Omniverse)"})]}),"\n",(0,t.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Create a deployment configuration for an Isaac-based mobile robot on a Jetson platform."}),"\n",(0,t.jsx)(e.li,{children:"Implement a health monitoring system for a deployed Isaac robot."}),"\n",(0,t.jsx)(e.li,{children:"Design a deployment strategy for a multi-robot system using Isaac applications."}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}}}]);